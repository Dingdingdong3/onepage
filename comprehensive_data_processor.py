#!/usr/bin/env python3
"""
ì „ì²´ ì§€ì—­ì˜ ì°¨ëŸ‰ ë° ì§€ìì²´ ë³´ì¡°ê¸ˆ ë°ì´í„° ì²˜ë¦¬
Google Sheetsì˜ ì§€ë°©ë¹„(ì§€ìì²´ ë³´ì¡°ê¸ˆ) ë°ì´í„° í†µí•©
"""

import json
from datetime import datetime
from collections import defaultdict

def load_existing_json():
    """ê¸°ì¡´ í¬ë¡¤ë§ëœ JSON ë°ì´í„° ë¡œë“œ"""
    with open('ev_subsidy_all_regions_20250712_191009.json', 'r', encoding='utf-8') as f:
        return json.load(f)

def process_all_regions_data():
    """ëª¨ë“  ì§€ì—­ì˜ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ í†µí•©ëœ êµ¬ì¡°ë¡œ ë³€í™˜"""
    
    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
    raw_data = load_existing_json()
    
    # ì „ì²´ ì°¨ëŸ‰ ëª©ë¡ (ì¤‘ë³µ ì œê±°)
    all_vehicles = {}
    
    # ì§€ì—­ë³„ ë³´ì¡°ê¸ˆ ì •ë³´
    region_subsidies = {}
    
    # ì œì¡°ì‚¬ë³„ ëª¨ë¸ ì •ë¦¬
    manufacturer_models = defaultdict(set)
    
    # ê° ì§€ì—­ ë°ì´í„° ì²˜ë¦¬
    for region, vehicles in raw_data.items():
        if not vehicles:
            continue
            
        # ì§€ì—­ë³„ ì§€ìì²´ ë³´ì¡°ê¸ˆ í‰ê·  ê³„ì‚°
        local_subsidies = []
        
        for vehicle in vehicles:
            # ì°¨ëŸ‰ ì •ë³´ ì •ë¦¬
            manufacturer = vehicle['manufacturer']
            model_detail = vehicle['model_detail']
            # ì½¤ë§ˆì™€ ì†Œìˆ˜ì  ì²˜ë¦¬
            national_str = vehicle['national_subsidy'].replace(',', '')
            local_str = vehicle['local_subsidy'].replace(',', '')
            
            national = int(float(national_str))
            local = int(float(local_str))  # ì§€ë°©ë¹„ = ì§€ìì²´ ë³´ì¡°ê¸ˆ
            
            # ì°¨ëŸ‰ ê³ ìœ  ID ìƒì„±
            vehicle_id = f"{manufacturer}_{model_detail}"
            
            # ì „ì²´ ì°¨ëŸ‰ ëª©ë¡ì— ì¶”ê°€ (ì¤‘ë³µ ì œê±°)
            if vehicle_id not in all_vehicles:
                all_vehicles[vehicle_id] = {
                    'manufacturer': manufacturer,
                    'model': model_detail,
                    'nationalSubsidy': national,
                    'category': vehicle['model']
                }
            
            # ì œì¡°ì‚¬ë³„ ëª¨ë¸ ì¶”ê°€
            manufacturer_models[manufacturer].add(model_detail)
            
            # ì§€ìì²´ ë³´ì¡°ê¸ˆ ìˆ˜ì§‘
            if local > 0:
                local_subsidies.append(local)
        
        # ì§€ì—­ë³„ í‰ê·  ì§€ìì²´ ë³´ì¡°ê¸ˆ ê³„ì‚°
        if local_subsidies:
            avg_subsidy = sum(local_subsidies) // len(local_subsidies)
            max_subsidy = max(local_subsidies)
            min_subsidy = min(local_subsidies)
            
            region_subsidies[region] = {
                'region': region,
                'avgSubsidy': avg_subsidy,
                'maxSubsidy': max_subsidy,
                'minSubsidy': min_subsidy,
                'vehicleCount': len(vehicles)
            }
    
    # ì°¨ëŸ‰ ëª©ë¡ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ê³  ì •ë ¬
    vehicles_list = sorted(all_vehicles.values(), 
                          key=lambda x: (x['manufacturer'], x['model']))
    
    # ì œì¡°ì‚¬ ëª©ë¡ ì •ë ¬
    manufacturers = sorted(manufacturer_models.keys())
    
    # ì§€ì—­ ëª©ë¡ ì •ë ¬
    regions_list = sorted(region_subsidies.values(), 
                         key=lambda x: x['avgSubsidy'], 
                         reverse=True)
    
    # ì „ì²´ ë°ì´í„° êµ¬ì¡°
    comprehensive_data = {
        'metadata': {
            'lastUpdated': datetime.now().isoformat(),
            'source': 'í™˜ê²½ë¶€ ì „ê¸°ì°¨ ë³´ì¡°ê¸ˆ ë°ì´í„° (ev.or.kr)',
            'year': 2025,
            'totalVehicles': len(vehicles_list),
            'totalManufacturers': len(manufacturers),
            'totalRegions': len(regions_list)
        },
        'vehicles': vehicles_list,
        'manufacturers': manufacturers,
        'regions': regions_list,
        'regionDetails': raw_data  # ì›ë³¸ ë°ì´í„°ë„ í¬í•¨
    }
    
    return comprehensive_data

def generate_optimized_data():
    """ìµœì í™”ëœ ë°ì´í„° ìƒì„±"""
    
    # ì „ì²´ ë°ì´í„° ì²˜ë¦¬
    data = process_all_regions_data()
    
    # í†µê³„ ì •ë³´ ì¶œë ¥
    print("ğŸ“Š ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ:")
    print(f"   - ì´ ì°¨ëŸ‰ ëª¨ë¸: {data['metadata']['totalVehicles']}ê°œ")
    print(f"   - ì œì¡°ì‚¬: {data['metadata']['totalManufacturers']}ê°œ")
    print(f"   - ì§€ì—­: {data['metadata']['totalRegions']}ê°œ")
    
    # ì§€ìì²´ ë³´ì¡°ê¸ˆ ìƒìœ„ 5ê°œ ì§€ì—­
    print("\nğŸ’° ì§€ìì²´ ë³´ì¡°ê¸ˆ ìƒìœ„ 5ê°œ ì§€ì—­:")
    for i, region in enumerate(data['regions'][:5]):
        print(f"   {i+1}. {region['region']}: í‰ê·  {region['avgSubsidy']}ë§Œì› (ìµœëŒ€ {region['maxSubsidy']}ë§Œì›)")
    
    # ì œì¡°ì‚¬ë³„ ì°¨ëŸ‰ ìˆ˜
    print("\nğŸš— ì œì¡°ì‚¬ë³„ ì°¨ëŸ‰ ëª¨ë¸ ìˆ˜:")
    manufacturer_count = defaultdict(int)
    for vehicle in data['vehicles']:
        manufacturer_count[vehicle['manufacturer']] += 1
    
    for manufacturer, count in sorted(manufacturer_count.items(), key=lambda x: x[1], reverse=True)[:5]:
        print(f"   - {manufacturer}: {count}ê°œ ëª¨ë¸")
    
    # íŒŒì¼ ì €ì¥
    filename = f"ev_comprehensive_data_{datetime.now().strftime('%Y%m%d')}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ë°ì´í„°ë¥¼ {filename} íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    
    # ê²½ëŸ‰í™”ëœ ë²„ì „ë„ ìƒì„± (regionDetails ì œì™¸)
    light_data = {
        'metadata': data['metadata'],
        'vehicles': data['vehicles'],
        'manufacturers': data['manufacturers'],
        'regions': data['regions']
    }
    
    light_filename = f"ev_data_light_{datetime.now().strftime('%Y%m%d')}.json"
    with open(light_filename, 'w', encoding='utf-8') as f:
        json.dump(light_data, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ê²½ëŸ‰ ë²„ì „ì„ {light_filename} íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    generate_optimized_data()