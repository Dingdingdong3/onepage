#!/opt/anaconda3/bin/python
# -*- coding: utf-8 -*-
"""
ì „ê¸°ì°¨ ë³´ì¡°ê¸ˆ í¬ë¡¤ë§ ì‹œìŠ¤í…œ (Selenium ëŒ€ì•ˆ ë²„ì „)
requests-html, Playwright, Pyppeteer ë“± ë‹¤ì–‘í•œ ë°©ë²• ì§€ì›
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import json
import os
from datetime import datetime
import hashlib
import time
import asyncio
import sys

# Google Sheets ê´€ë ¨ imports (ì„ íƒì )
try:
    import gspread
    from google.oauth2.service_account import Credentials

    GOOGLE_SHEETS_AVAILABLE = True
except ImportError:
    GOOGLE_SHEETS_AVAILABLE = False
    print("âš ï¸  êµ¬ê¸€ ì‹œíŠ¸ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´ ì„¤ì¹˜í•˜ì„¸ìš”: /opt/anaconda3/bin/pip install gspread google-auth")

# ì„ íƒì  imports (ì„¤ì¹˜ëœ ë¼ì´ë¸ŒëŸ¬ë¦¬ì— ë”°ë¼)
try:
    from requests_html import HTMLSession, AsyncHTMLSession

    REQUESTS_HTML_AVAILABLE = True
except ImportError:
    REQUESTS_HTML_AVAILABLE = False
    print("âš ï¸  requests-htmlì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. pip install requests-html")

try:
    from playwright.sync_api import sync_playwright
    from playwright.async_api import async_playwright

    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False
    print("âš ï¸  playwrightê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. pip install playwright && playwright install")

try:
    import pyppeteer

    PYPPETEER_AVAILABLE = True
except ImportError:
    PYPPETEER_AVAILABLE = False
    print("âš ï¸  pyppeteerê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. pip install pyppeteer")


class GoogleSheetsManager:
    """êµ¬ê¸€ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ê´€ë¦¬ í´ë˜ìŠ¤"""

    def __init__(self, credentials_file, spreadsheet_id):
        if not GOOGLE_SHEETS_AVAILABLE:
            raise ImportError("êµ¬ê¸€ ì‹œíŠ¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ. /opt/anaconda3/bin/pip install gspread google-auth")

        self.scope = [
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive"
        ]

        try:
            self.credentials = Credentials.from_service_account_file(
                credentials_file,
                scopes=self.scope
            )
            self.gc = gspread.authorize(self.credentials)
            self.spreadsheet = self.gc.open_by_key(spreadsheet_id)
            print(f"âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì„±ê³µ: {self.spreadsheet.title}")
        except Exception as e:
            print(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì—°ê²° ì‹¤íŒ¨: {e}")
            raise

    def upload_national_subsidy(self, df):
        """êµ­ê³  ë³´ì¡°ê¸ˆ ë°ì´í„° ì—…ë¡œë“œ"""
        try:
            print(f"ğŸ“Š êµ­ê³ ë³´ì¡°ê¸ˆ ë°ì´í„° ì—…ë¡œë“œ ì‹œì‘: {len(df)}ê°œ í•­ëª©")
            print(f"ğŸ” DataFrame ì •ë³´: ì»¬ëŸ¼={list(df.columns)}, íƒ€ì…={type(df)}")

            # 'êµ­ê³ ë³´ì¡°ê¸ˆ' ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
            try:
                worksheet = self.spreadsheet.worksheet('êµ­ê³ ë³´ì¡°ê¸ˆ')
                print("âœ… ê¸°ì¡´ 'êµ­ê³ ë³´ì¡°ê¸ˆ' ì‹œíŠ¸ ë°œê²¬")
            except gspread.WorksheetNotFound:
                worksheet = self.spreadsheet.add_worksheet(title='êµ­ê³ ë³´ì¡°ê¸ˆ', rows=1000, cols=10)
                print("âœ… ìƒˆ 'êµ­ê³ ë³´ì¡°ê¸ˆ' ì‹œíŠ¸ ìƒì„±")

            # ê¸°ì¡´ ë°ì´í„° ì§€ìš°ê¸°
            worksheet.clear()
            print("ğŸ§¹ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")

            # í—¤ë”ì™€ ë°ì´í„° ì¤€ë¹„
            headers = list(df.columns)
            print(f"ğŸ“‹ í—¤ë”: {headers}")

            # DataFrameì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            data_list = df.values.tolist()
            print(f"ğŸ“Š ë°ì´í„° {len(data_list)}ê°œ í–‰ ì¤€ë¹„ ì™„ë£Œ")
            if data_list:
                print(f"ğŸ” ì²« ë²ˆì§¸ ë°ì´í„° ìƒ˜í”Œ: {data_list[0]}")
                print(f"ğŸ” ë°ì´í„° íƒ€ì… í™•ì¸: {[type(item) for item in data_list[0]]}")

            # ì—…ë°ì´íŠ¸ ì‹œê°„ ì¶”ê°€
            update_time = f"ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"

            # í—¤ë” ì…ë ¥
            try:
                worksheet.update(values=[headers], range_name='A1:D1')
                print("âœ… í—¤ë” ì…ë ¥ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ í—¤ë” ì…ë ¥ ì‹¤íŒ¨: {e}")
                # ëŒ€ì•ˆ ë°©ë²• ì‹œë„
                worksheet.update(range_name='A1:D1', values=[headers])
                print("âœ… í—¤ë” ì…ë ¥ ì™„ë£Œ (ëŒ€ì•ˆ ë°©ë²•)")

            # ë°ì´í„° ì…ë ¥
            if data_list:
                # ë°ì´í„° ë²”ìœ„ ê³„ì‚°
                end_row = len(data_list) + 1
                range_notation = f'A2:D{end_row}'
                print(f"ğŸ“ ë°ì´í„° ì…ë ¥ ë²”ìœ„: {range_notation}")

                try:
                    worksheet.update(values=data_list, range_name=range_notation)
                    print("âœ… ë°ì´í„° ì…ë ¥ ì™„ë£Œ")
                except Exception as e:
                    print(f"âŒ ë°ì´í„° ì…ë ¥ ì‹¤íŒ¨: {e}")
                    # ëŒ€ì•ˆ ë°©ë²• ì‹œë„
                    worksheet.update(range_name=range_notation, values=data_list)
                    print("âœ… ë°ì´í„° ì…ë ¥ ì™„ë£Œ (ëŒ€ì•ˆ ë°©ë²•)")
            else:
                print("âš ï¸ ì…ë ¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

            # ì—…ë°ì´íŠ¸ ì‹œê°„ ì…ë ¥
            try:
                worksheet.update(values=[[update_time]], range_name='F1')
                print("âœ… ì—…ë°ì´íŠ¸ ì‹œê°„ ì…ë ¥ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ì—…ë°ì´íŠ¸ ì‹œê°„ ì…ë ¥ ì‹¤íŒ¨: {e}")

            # í—¤ë” ì„œì‹ ì„¤ì •
            try:
                worksheet.format('A1:D1', {
                    "backgroundColor": {"red": 0.2, "green": 0.6, "blue": 1.0},
                    "textFormat": {"bold": True, "foregroundColor": {"red": 1, "green": 1, "blue": 1}}
                })
                print("âœ… í—¤ë” ì„œì‹ ì„¤ì • ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ í—¤ë” ì„œì‹ ì„¤ì • ì‹¤íŒ¨: {e}")

            print(f"ğŸ“Š êµ¬ê¸€ ì‹œíŠ¸ êµ­ê³ ë³´ì¡°ê¸ˆ {len(df)}ê°œ ì—…ë¡œë“œ ì™„ë£Œ")

        except Exception as e:
            print(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ êµ­ê³ ë³´ì¡°ê¸ˆ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()

    def upload_local_subsidy(self, df):
        """ì§€ìì²´ ë³´ì¡°ê¸ˆ ë°ì´í„° ì—…ë¡œë“œ"""
        try:
            print(f"ğŸ¢ ì§€ìì²´ë³´ì¡°ê¸ˆ ë°ì´í„° ì—…ë¡œë“œ ì‹œì‘: {len(df)}ê°œ í•­ëª©")
            print(f"ğŸ” DataFrame ì •ë³´: ì»¬ëŸ¼={list(df.columns)}, íƒ€ì…={type(df)}")

            # 'ì§€ìì²´ë³´ì¡°ê¸ˆ' ì‹œíŠ¸ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±
            try:
                worksheet = self.spreadsheet.worksheet('ì§€ìì²´ë³´ì¡°ê¸ˆ')
                print("âœ… ê¸°ì¡´ 'ì§€ìì²´ë³´ì¡°ê¸ˆ' ì‹œíŠ¸ ë°œê²¬")
            except gspread.WorksheetNotFound:
                worksheet = self.spreadsheet.add_worksheet(title='ì§€ìì²´ë³´ì¡°ê¸ˆ', rows=1000, cols=10)
                print("âœ… ìƒˆ 'ì§€ìì²´ë³´ì¡°ê¸ˆ' ì‹œíŠ¸ ìƒì„±")

            # ê¸°ì¡´ ë°ì´í„° ì§€ìš°ê¸°
            worksheet.clear()
            print("ğŸ§¹ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ ì™„ë£Œ")

            # í—¤ë”ì™€ ë°ì´í„° ì¤€ë¹„
            headers = list(df.columns)
            print(f"ğŸ“‹ í—¤ë”: {headers}")

            # DataFrameì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            data_list = df.values.tolist()
            print(f"ğŸ“Š ë°ì´í„° {len(data_list)}ê°œ í–‰ ì¤€ë¹„ ì™„ë£Œ")
            if data_list:
                print(f"ğŸ” ì²« ë²ˆì§¸ ë°ì´í„° ìƒ˜í”Œ: {data_list[0]}")
                print(f"ğŸ” ë°ì´í„° íƒ€ì… í™•ì¸: {[type(item) for item in data_list[0]]}")

            # ì—…ë°ì´íŠ¸ ì‹œê°„ ì¶”ê°€
            update_time = f"ì—…ë°ì´íŠ¸: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"

            # í—¤ë” ì…ë ¥
            try:
                worksheet.update(values=[headers], range_name='A1:B1')
                print("âœ… í—¤ë” ì…ë ¥ ì™„ë£Œ")
            except Exception as e:
                print(f"âŒ í—¤ë” ì…ë ¥ ì‹¤íŒ¨: {e}")
                # ëŒ€ì•ˆ ë°©ë²• ì‹œë„
                worksheet.update(range_name='A1:B1', values=[headers])
                print("âœ… í—¤ë” ì…ë ¥ ì™„ë£Œ (ëŒ€ì•ˆ ë°©ë²•)")

            # ë°ì´í„° ì…ë ¥
            if data_list:
                # ë°ì´í„° ë²”ìœ„ ê³„ì‚°
                end_row = len(data_list) + 1
                range_notation = f'A2:B{end_row}'
                print(f"ğŸ“ ë°ì´í„° ì…ë ¥ ë²”ìœ„: {range_notation}")

                try:
                    worksheet.update(values=data_list, range_name=range_notation)
                    print("âœ… ë°ì´í„° ì…ë ¥ ì™„ë£Œ")
                except Exception as e:
                    print(f"âŒ ë°ì´í„° ì…ë ¥ ì‹¤íŒ¨: {e}")
                    # ëŒ€ì•ˆ ë°©ë²• ì‹œë„
                    worksheet.update(range_name=range_notation, values=data_list)
                    print("âœ… ë°ì´í„° ì…ë ¥ ì™„ë£Œ (ëŒ€ì•ˆ ë°©ë²•)")
            else:
                print("âš ï¸ ì…ë ¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

            # ì—…ë°ì´íŠ¸ ì‹œê°„ ì…ë ¥
            try:
                worksheet.update(values=[[update_time]], range_name='D1')
                print("âœ… ì—…ë°ì´íŠ¸ ì‹œê°„ ì…ë ¥ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ì—…ë°ì´íŠ¸ ì‹œê°„ ì…ë ¥ ì‹¤íŒ¨: {e}")

            # í—¤ë” ì„œì‹ ì„¤ì •
            try:
                worksheet.format('A1:B1', {
                    "backgroundColor": {"red": 1.0, "green": 0.6, "blue": 0.2},
                    "textFormat": {"bold": True, "foregroundColor": {"red": 1, "green": 1, "blue": 1}}
                })
                print("âœ… í—¤ë” ì„œì‹ ì„¤ì • ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ í—¤ë” ì„œì‹ ì„¤ì • ì‹¤íŒ¨: {e}")

            print(f"ğŸ¢ êµ¬ê¸€ ì‹œíŠ¸ ì§€ìì²´ë³´ì¡°ê¸ˆ {len(df)}ê°œ ì—…ë¡œë“œ ì™„ë£Œ")

        except Exception as e:
            print(f"âŒ êµ¬ê¸€ ì‹œíŠ¸ ì§€ìì²´ë³´ì¡°ê¸ˆ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()


class EVSubsidyManager:
    def __init__(self, data_dir='ev_data', method='auto',
                 use_google_sheets=False, credentials_file=None, spreadsheet_id=None):
        self.url = "https://www.ev.or.kr/nportal/buySupprt/initBuySubsidySupprtAction.do"
        self.data_dir = data_dir
        self.national_file = os.path.join(data_dir, 'national_subsidy.csv')
        self.local_file = os.path.join(data_dir, 'local_subsidy.csv')
        self.metadata_file = os.path.join(data_dir, 'metadata.json')

        # í¬ë¡¤ë§ ë°©ë²• ì„ íƒ (auto, requests, requests-html, playwright, pyppeteer)
        self.method = method

        # êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì •
        self.use_google_sheets = use_google_sheets
        print(f"ğŸ”§ êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì •:")
        print(f"   - use_google_sheets: {use_google_sheets}")
        print(f"   - credentials_file: {credentials_file}")
        print(f"   - spreadsheet_id: {spreadsheet_id}")
        print(f"   - GOOGLE_SHEETS_AVAILABLE: {GOOGLE_SHEETS_AVAILABLE}")

        if use_google_sheets and credentials_file and spreadsheet_id and GOOGLE_SHEETS_AVAILABLE:
            try:
                print("ğŸ“Š êµ¬ê¸€ ì‹œíŠ¸ ë§¤ë‹ˆì € ìƒì„± ì‹œë„...")
                self.sheets_manager = GoogleSheetsManager(credentials_file, spreadsheet_id)
                print("âœ… êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ í™œì„±í™”")
            except Exception as e:
                print(f"âš ï¸ êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ ì‹¤íŒ¨, CSVë§Œ ì €ì¥: {e}")
                import traceback
                traceback.print_exc()
                self.sheets_manager = None
        else:
            self.sheets_manager = None
            if use_google_sheets:
                print("âš ï¸ êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì • ë¶ˆì™„ì „:")
                if not GOOGLE_SHEETS_AVAILABLE:
                    print("   - GOOGLE_SHEETS_AVAILABLE = False")
                if not credentials_file:
                    print("   - credentials_file ì—†ìŒ")
                if not spreadsheet_id:
                    print("   - spreadsheet_id ì—†ìŒ")
                print("   â†’ CSVë§Œ ì €ì¥ë©ë‹ˆë‹¤")

        # ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(data_dir, exist_ok=True)

        # ë©”íƒ€ë°ì´í„° ë¡œë“œ
        self.metadata = self.load_metadata()

        # ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²• í™•ì¸
        self.available_methods = self._check_available_methods()
        print(f"ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ í¬ë¡¤ë§ ë°©ë²•: {', '.join(self.available_methods)}")

    def _check_available_methods(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ í¬ë¡¤ë§ ë°©ë²• í™•ì¸"""
        methods = ['requests']  # ê¸°ë³¸ì ìœ¼ë¡œ requestsëŠ” í•­ìƒ ì‚¬ìš© ê°€ëŠ¥

        if REQUESTS_HTML_AVAILABLE:
            methods.append('requests-html')
        if PLAYWRIGHT_AVAILABLE:
            methods.append('playwright')
        if PYPPETEER_AVAILABLE:
            methods.append('pyppeteer')

        return methods

    def _select_method(self):
        """ìµœì ì˜ í¬ë¡¤ë§ ë°©ë²• ìë™ ì„ íƒ"""
        if self.method != 'auto':
            return self.method

        # ìš°ì„ ìˆœìœ„: requests-html > playwright > pyppeteer > requests
        # JavaScript ë Œë”ë§ ê°€ëŠ¥í•œ ë°©ë²•ì„ ìš°ì„  ì„ íƒ
        if 'requests-html' in self.available_methods:
            return 'requests-html'
        elif 'playwright' in self.available_methods:
            return 'playwright'
        elif 'pyppeteer' in self.available_methods:
            print("ğŸ’¡ pyppeteer ì‚¬ìš© - JavaScript ë Œë”ë§ìœ¼ë¡œ ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘ ê°€ëŠ¥")
            return 'pyppeteer'
        else:
            print("âš ï¸  JavaScript ë Œë”ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ì–´ ì œí•œì ì¸ ë°ì´í„°ë§Œ ìˆ˜ì§‘ë©ë‹ˆë‹¤.")
            return 'requests'

    def load_metadata(self):
        """ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        if os.path.exists(self.metadata_file):
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {
            'last_updated': None,
            'national_hash': None,
            'local_hash': None,
            'total_runs': 0,
            'method_used': None
        }

    def save_metadata(self):
        """ë©”íƒ€ë°ì´í„° ì €ì¥"""
        with open(self.metadata_file, 'w', encoding='utf-8') as f:
            json.dump(self.metadata, f, ensure_ascii=False, indent=2)

    def calculate_data_hash(self, data):
        """ë°ì´í„°ì˜ í•´ì‹œê°’ ê³„ì‚°"""
        data_str = json.dumps(data, sort_keys=True, ensure_ascii=False)
        return hashlib.md5(data_str.encode()).hexdigest()

    # ë°©ë²• 1: ê¸°ë³¸ requests + BeautifulSoup
    def crawl_with_requests(self):
        """ê¸°ë³¸ requestsë¥¼ ì‚¬ìš©í•œ í¬ë¡¤ë§"""
        try:
            print("ğŸ“¡ requests ë°©ë²•ìœ¼ë¡œ í¬ë¡¤ë§ ì‹œì‘...")
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.6,en;q=0.4',
                'Accept-Encoding': 'gzip, deflate, br',
                'DNT': '1',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1'
            }

            session = requests.Session()
            response = session.get(self.url, headers=headers, timeout=30)
            response.raise_for_status()

            soup = BeautifulSoup(response.content, 'html.parser')
            return self.extract_both_tables(soup, "requests")

        except Exception as e:
            print(f"âŒ requests í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return None, None

    # ë°©ë²• 2: requests-html (ê°€ì¥ ê°„ë‹¨í•œ JavaScript ë Œë”ë§)
    def crawl_with_requests_html(self):
        """requests-htmlì„ ì‚¬ìš©í•œ í¬ë¡¤ë§"""
        if not REQUESTS_HTML_AVAILABLE:
            print("âŒ requests-htmlì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            return None, None

        try:
            print("ğŸŒ requests-html ë°©ë²•ìœ¼ë¡œ í¬ë¡¤ë§ ì‹œì‘...")
            session = HTMLSession()

            # ìš”ì²­
            r = session.get(self.url)

            # JavaScript ë Œë”ë§ (ìµœëŒ€ 10ì´ˆ ëŒ€ê¸°)
            print("â³ JavaScript ë Œë”ë§ ì¤‘... (ìµœëŒ€ 10ì´ˆ)")
            r.html.render(wait=3, timeout=10)

            # BeautifulSoupìœ¼ë¡œ íŒŒì‹±
            soup = BeautifulSoup(r.html.html, 'html.parser')

            # ì„¸ì…˜ ì •ë¦¬
            session.close()

            return self.extract_both_tables(soup, "requests-html")

        except Exception as e:
            print(f"âŒ requests-html í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return None, None

    # ë°©ë²• 3: Playwright (í˜„ëŒ€ì ì´ê³  ë¹ ë¦„)
    def crawl_with_playwright(self):
        """Playwrightë¥¼ ì‚¬ìš©í•œ í¬ë¡¤ë§"""
        if not PLAYWRIGHT_AVAILABLE:
            print("âŒ Playwrightê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            return None, None

        try:
            print("ğŸ­ Playwright ë°©ë²•ìœ¼ë¡œ í¬ë¡¤ë§ ì‹œì‘...")

            with sync_playwright() as p:
                # ë¸Œë¼ìš°ì € ì‹œì‘ (headless ëª¨ë“œ)
                browser = p.chromium.launch(headless=True)
                page = browser.new_page()

                # User-Agent ì„¤ì •
                page.set_extra_http_headers({
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                })

                # í˜ì´ì§€ ë¡œë“œ
                print("ğŸ“„ í˜ì´ì§€ ë¡œë”© ì¤‘...")
                page.goto(self.url, wait_until='networkidle', timeout=30000)

                # í…Œì´ë¸”ì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
                try:
                    page.wait_for_selector('table.table01.fz15', timeout=10000)
                    print("âœ… í…Œì´ë¸” ë¡œë“œ ì™„ë£Œ")
                except:
                    print("âš ï¸  í…Œì´ë¸” ë¡œë“œ ëŒ€ê¸° ì‹œê°„ ì´ˆê³¼")

                # HTML ì¶”ì¶œ
                html_content = page.content()
                browser.close()

                # BeautifulSoupìœ¼ë¡œ íŒŒì‹±
                soup = BeautifulSoup(html_content, 'html.parser')
                return self.extract_both_tables(soup, "playwright")

        except Exception as e:
            print(f"âŒ Playwright í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return None, None

    # ë°©ë²• 4: Pyppeteer (ë¹„ë™ê¸° ì²˜ë¦¬)
    def crawl_with_pyppeteer(self):
        """Pyppeteerë¥¼ ì‚¬ìš©í•œ í¬ë¡¤ë§"""
        if not PYPPETEER_AVAILABLE:
            print("âŒ Pyppeteerê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            return None, None

        try:
            print("ğŸ Pyppeteer ë°©ë²•ìœ¼ë¡œ í¬ë¡¤ë§ ì‹œì‘...")

            # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(self._pyppeteer_crawl())
            loop.close()

            return result

        except Exception as e:
            print(f"âŒ Pyppeteer í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return None, None

    async def _pyppeteer_crawl(self):
        """Pyppeteer ë¹„ë™ê¸° í¬ë¡¤ë§ í•¨ìˆ˜"""
        browser = await pyppeteer.launch(
            headless=True,
            args=[
                '--no-sandbox',
                '--disable-setuid-sandbox',
                '--disable-dev-shm-usage',
                '--disable-gpu'
            ]
        )
        page = await browser.newPage()

        # User-Agent ì„¤ì •
        await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')

        # í˜ì´ì§€ ë¡œë“œ
        print("ğŸ“„ í˜ì´ì§€ ë¡œë”© ì¤‘...")
        response = await page.goto(self.url, {'waitUntil': 'networkidle0', 'timeout': 30000})
        print(f"ğŸ“Š í˜ì´ì§€ ì‘ë‹µ ìƒíƒœ: {response.status}")

        # í˜„ì¬ URL í™•ì¸
        current_url = page.url
        print(f"ğŸ”— í˜„ì¬ URL: {current_url}")

        # í˜ì´ì§€ ì œëª© í™•ì¸
        title = await page.title()
        print(f"ğŸ“„ í˜ì´ì§€ ì œëª©: {title}")

        # íƒ­ ë˜ëŠ” JavaScript ë™ì‘ í™•ì¸ì„ ìœ„í•´ ì¶”ê°€ ëŒ€ê¸°
        print("â³ JavaScript ì‹¤í–‰ ëŒ€ê¸° ì¤‘...")
        await page.waitFor(5000)  # 5ì´ˆ ëŒ€ê¸°

        # ì§€ìì²´ ë³´ì¡°ê¸ˆ íƒ­ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  í´ë¦­ ì‹œë„
        try:
            # ì§€ìì²´ ë³´ì¡°ê¸ˆ íƒ­ ë˜ëŠ” ë²„íŠ¼ ì°¾ê¸°
            tab_selectors = [
                'a[href*="ì§€ìì²´"]',
                'button:contains("ì§€ìì²´")',
                '.tab:contains("ì§€ìì²´")',
                '[data-tab*="local"]',
                '[data-tab*="ì§€ìì²´"]'
            ]

            tab_clicked = False
            for selector in tab_selectors:
                try:
                    await page.click(selector)
                    print(f"âœ… ì§€ìì²´ ë³´ì¡°ê¸ˆ íƒ­ í´ë¦­ ì„±ê³µ: {selector}")
                    await page.waitFor(3000)  # íƒ­ ì „í™˜ ëŒ€ê¸°
                    tab_clicked = True
                    break
                except:
                    continue

            if not tab_clicked:
                print("âš ï¸  ì§€ìì²´ ë³´ì¡°ê¸ˆ íƒ­ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            print(f"âš ï¸  íƒ­ í´ë¦­ ì‹œë„ ì¤‘ ì˜¤ë¥˜: {e}")

        # í…Œì´ë¸” ëŒ€ê¸° - ì—¬ëŸ¬ ì„ íƒìë¡œ ì‹œë„
        selectors_to_try = [
            'table.table01.fz15',
            'table.table01',
            'table',
            '.subWrap table'
        ]

        table_found = False
        for selector in selectors_to_try:
            try:
                elements = await page.querySelectorAll(selector)
                if elements:
                    print(f"âœ… í…Œì´ë¸” ë°œê²¬: {len(elements)}ê°œ (ì„ íƒì: {selector})")
                    table_found = True
                    break
            except:
                continue

        if not table_found:
            print("âš ï¸  í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # í˜ì´ì§€ì˜ ëª¨ë“  í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘
        try:
            tables_info = await page.evaluate('''() => {
                const tables = document.querySelectorAll('table');
                return Array.from(tables).map((table, index) => {
                    const rows = table.querySelectorAll('tr');
                    const headers = Array.from(table.querySelectorAll('th, tr:first-child td')).map(h => h.textContent.trim());
                    return {
                        index: index,
                        className: table.className,
                        rowCount: rows.length,
                        headers: headers.slice(0, 5), // ì²˜ìŒ 5ê°œ í—¤ë”ë§Œ
                        parentDiv: table.closest('div') ? table.closest('div').className : 'none'
                    };
                });
            }''')

            print(f"ğŸ” í˜ì´ì§€ ë‚´ ëª¨ë“  í…Œì´ë¸” ì •ë³´:")
            for info in tables_info:
                print(f"   í…Œì´ë¸” {info['index']}: í´ë˜ìŠ¤='{info['className']}', í–‰ìˆ˜={info['rowCount']}")
                print(f"   í—¤ë”: {info['headers']}")
                print(f"   ë¶€ëª¨ div: {info['parentDiv']}")
                print()

        except Exception as e:
            print(f"âš ï¸  í…Œì´ë¸” ì •ë³´ ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")

        # HTML ì¶”ì¶œ
        html_content = await page.content()

        # HTML ì¼ë¶€ ì €ì¥ (ë””ë²„ê¹…ìš©)
        debug_html_file = os.path.join(self.data_dir, 'debug_page_source.html')
        with open(debug_html_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        print(f"ğŸ“ í˜ì´ì§€ ì†ŒìŠ¤ ì €ì¥: {debug_html_file}")

        await browser.close()

        # BeautifulSoupìœ¼ë¡œ íŒŒì‹±
        soup = BeautifulSoup(html_content, 'html.parser')
        return self.extract_both_tables(soup, "pyppeteer")

    def extract_both_tables(self, soup, method_name):
        """êµ­ê³  ë³´ì¡°ê¸ˆê³¼ ì§€ìì²´ ë³´ì¡°ê¸ˆ í…Œì´ë¸” ì¶”ì¶œ"""
        print(f"ğŸ” {method_name} ë°©ë²•ìœ¼ë¡œ í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ ì¤‘...")

        # ëª¨ë“  í…Œì´ë¸” ë¶„ì„ ë° ë¶„ë¥˜
        all_tables = soup.find_all('table', class_='table01 fz15')
        print(f"ğŸ” ì´ {len(all_tables)}ê°œ í…Œì´ë¸” ë°œê²¬")

        national_table = None
        local_table = None

        for i, table in enumerate(all_tables):
            # í—¤ë” í™•ì¸
            header_row = table.find('thead')
            if header_row:
                headers = [th.get_text(strip=True) for th in header_row.find_all(['th', 'td'])]
            else:
                first_row = table.find('tr')
                headers = [td.get_text(strip=True) for td in first_row.find_all(['th', 'td'])] if first_row else []

            print(f"   í…Œì´ë¸” {i}: {headers}")

            # ì§€ìì²´ ë³´ì¡°ê¸ˆ í…Œì´ë¸” ì‹ë³„ (ì‹œë„, ì „ê¸°ìë™ì°¨ ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)
            if any('ì‹œë„' in h for h in headers) and any('ì „ê¸°' in h for h in headers):
                local_table = table
                print(f"   âœ… í…Œì´ë¸” {i}ë¥¼ ì§€ìì²´ ë³´ì¡°ê¸ˆìœ¼ë¡œ ì‹ë³„")

            # êµ­ê³  ë³´ì¡°ê¸ˆ í…Œì´ë¸” ì‹ë³„ (êµ¬ë¶„, ì œì¡°ì‚¬, ì°¨ì¢…, ë³´ì¡°ê¸ˆ ì»¬ëŸ¼ì´ ìˆê³  í–‰ì´ ë§ì€ ê²½ìš°)
            elif (any('êµ¬ë¶„' in h for h in headers) and
                  any('ì œì¡°' in h or 'ìˆ˜ì…' in h for h in headers) and
                  any('ì°¨ì¢…' in h for h in headers) and
                  any('ë³´ì¡°ê¸ˆ' in h for h in headers)):

                # í–‰ ìˆ˜ í™•ì¸
                tbody = table.find('tbody')
                if tbody:
                    row_count = len(tbody.find_all('tr'))
                    if row_count > 10 and national_table is None:  # í–‰ì´ ë§ì€ ì²« ë²ˆì§¸ í…Œì´ë¸”
                        national_table = table
                        print(f"   âœ… í…Œì´ë¸” {i}ë¥¼ êµ­ê³  ë³´ì¡°ê¸ˆìœ¼ë¡œ ì‹ë³„ (í–‰ìˆ˜: {row_count})")

        # êµ­ê³  ë³´ì¡°ê¸ˆ ë°ì´í„° ì¶”ì¶œ
        national_data = []
        if national_table:
            national_div = national_table.find_parent('div')
            national_data = self.extract_table_from_div(national_div, "êµ­ê³  ë³´ì¡°ê¸ˆ")

            # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ëŒ€ì•ˆ íŒŒì„œ ì‹œë„
            if len(national_data) < 90:
                print(f"ğŸ”„ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì ìŒ ({len(national_data)}ê°œ), ëŒ€ì•ˆ íŒŒì„œ ì‹œë„...")
                alternative_data = self.use_alternative_html_parser(soup)
                if alternative_data and len(alternative_data) > len(national_data):
                    print(f"âœ… ëŒ€ì•ˆ íŒŒì„œë¡œ ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘: {len(alternative_data)}ê°œ")
                    national_data = alternative_data
        else:
            print("âŒ êµ­ê³  ë³´ì¡°ê¸ˆ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ì§€ìì²´ ë³´ì¡°ê¸ˆ ë°ì´í„° ì¶”ì¶œ
        local_data = []
        if local_table:
            local_div = local_table.find_parent('div')
            local_data = self.extract_local_subsidy_table(local_table)
        else:
            print("âŒ ì§€ìì²´ ë³´ì¡°ê¸ˆ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # ë©”íƒ€ë°ì´í„°ì— ì‚¬ìš©ëœ ë°©ë²• ê¸°ë¡
        self.metadata['method_used'] = method_name

        return national_data, local_data

    def use_alternative_html_parser(self, soup):
        """ëŒ€ì•ˆ HTML íŒŒì„œ - ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘ ì‹œë„"""
        print("ğŸ”„ ëŒ€ì•ˆ íŒŒì„œ ì‹¤í–‰ ì¤‘...")

        # ëª¨ë“  í…Œì´ë¸”ì—ì„œ ì „ê¸°ì°¨ ê´€ë ¨ ë°ì´í„° ìˆ˜ì§‘
        all_data = []
        all_tables = soup.find_all('table')

        for table in all_tables:
            rows = table.find_all('tr')
            for row in rows:
                cells = row.find_all(['td', 'th'])
                if len(cells) >= 3:
                    cell_texts = [cell.get_text(strip=True) for cell in cells]

                    # ì „ê¸°ì°¨ ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
                    row_text = ' '.join(cell_texts).lower()
                    if any(keyword in row_text for keyword in ['ì „ê¸°', 'ev', 'electric', 'ì•„ì´ì˜¤ë‹‰', 'ì½”ë‚˜']):
                        # ê¸°ë³¸ êµ¬ì¡°ë¡œ ë§¤í•‘
                        if len(cell_texts) >= 4:
                            data_row = {
                                'ì°¨ëŸ‰êµ¬ë¶„': cell_texts[0] if cell_texts[0] else 'ìŠ¹ìš©',
                                'ì œì¡°ì‚¬': cell_texts[1],
                                'ëª¨ë¸ëª…': cell_texts[2],
                                'êµ­ê³ ë³´ì¡°ê¸ˆ': cell_texts[3] if cell_texts[3].isdigit() else '0'
                            }
                            all_data.append(data_row)

        return all_data

    def extract_local_subsidy_table(self, table):
        """ì§€ìì²´ ë³´ì¡°ê¸ˆ í…Œì´ë¸” ì „ìš© ì¶”ì¶œ í•¨ìˆ˜"""
        print("ğŸ¢ ì§€ìì²´ ë³´ì¡°ê¸ˆ í…Œì´ë¸” ì²˜ë¦¬ ì¤‘...")

        # í—¤ë” ì¶”ì¶œ
        header_row = table.find('thead')
        if header_row:
            headers = [th.get_text(strip=True) for th in header_row.find_all(['th', 'td'])]
        else:
            first_row = table.find('tr')
            headers = [td.get_text(strip=True) for td in first_row.find_all(['th', 'td'])] if first_row else []

        print(f"ğŸ“‹ ì§€ìì²´ ë³´ì¡°ê¸ˆ í—¤ë”: {headers}")

        # tbodyì—ì„œ ë°ì´í„° í–‰ ì¶”ì¶œ
        tbody = table.find('tbody')
        if not tbody:
            print("âŒ ì§€ìì²´ ë³´ì¡°ê¸ˆ tbodyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

        rows = tbody.find_all('tr')
        data = []

        for row in rows:
            cells = row.find_all(['td', 'th'])
            if len(cells) >= 2:  # ìµœì†Œ 2ê°œ ì»¬ëŸ¼ (ì§€ì—­, ë³´ì¡°ê¸ˆ)
                row_data = {}

                for i, cell in enumerate(cells):
                    if i < len(headers):
                        header_name = headers[i]
                        cell_text = cell.get_text(strip=True)
                        row_data[header_name] = cell_text

                # ë¹ˆ í–‰ì´ ì•„ë‹Œ ê²½ìš° ì¶”ê°€
                if any(value.strip() for value in row_data.values()):
                    # ì§€ìì²´ ë³´ì¡°ê¸ˆ ë°ì´í„° í‘œì¤€í™”
                    standardized = self._standardize_local_subsidy_data(row_data)
                    if standardized:
                        data.append(standardized)

        print(f"âœ… ì§€ìì²´ ë³´ì¡°ê¸ˆ ë°ì´í„° {len(data)}ê°œ ì¶”ì¶œ ì™„ë£Œ")
        return data

    def extract_table_from_div(self, div_element, subsidy_type):
        """íŠ¹ì • div ë‚´ì˜ í…Œì´ë¸” ë°ì´í„° ì¶”ì¶œ (ì „ê¸°ìë™ì°¨ë§Œ í•„í„°ë§, rowspan ì²˜ë¦¬ ê°œì„ )"""
        if not div_element:
            print(f"âŒ {subsidy_type} divë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

        table = div_element.find('table', class_='table01 fz15')
        if not table:
            print(f"âŒ {subsidy_type} í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

        data = []

        # í—¤ë” ì¶”ì¶œ
        header_row = table.find('thead')
        if header_row:
            headers = [th.get_text(strip=True) for th in header_row.find_all(['th', 'td'])]
        else:
            first_row = table.find('tr')
            if first_row:
                headers = [td.get_text(strip=True) for td in first_row.find_all(['th', 'td'])]
            else:
                print(f"âŒ {subsidy_type} í—¤ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []

        # ë¶ˆì™„ì „í•œ í—¤ë” ì •ë¦¬ (5ë²ˆì§¸ ì»¬ëŸ¼ ì œê±°)
        if len(headers) > 4:
            headers = headers[:4]

        print(f"ğŸ“‹ {subsidy_type} í—¤ë”: {headers}")

        # tbodyì—ì„œ ë°ì´í„° í–‰ ì¶”ì¶œ
        tbody = table.find('tbody')
        if not tbody:
            print(f"âŒ {subsidy_type} tbodyë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

        rows = tbody.find_all('tr')

        # rowspan ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³€ìˆ˜ë“¤
        rowspan_values = {}  # {column_index: {'value': str, 'remaining': int}}
        electric_keywords = ['ì „ê¸°', 'EV', 'electric', 'Electrified', 'e-', 'ì•„ì´ì˜¤ë‹‰', 'ë ˆì´', 'EQC', 'EQS', 'Model', 'ë³¼íŠ¸',
                             'ì½”ë‚˜', 'KONA', 'GV60', 'GV70', 'ATTO', 'BYD', 'ì¼ë ‰íŠ¸ë¦­', 'ìºìŠ¤í¼', 'EV6', 'EV9', 'bZ4X',
                             'Taycan', 'e-tron', 'EQA', 'EQB', 'EQV', 'iX3', 'i7', 'Polestar', 'XC40', 'C40', 'EX90']
        total_rows = 0
        filtered_rows = 0

        # ëˆ„ë½ ë¶„ì„ìš© ë³€ìˆ˜
        skipped_reasons = {
            'ë¹ˆ_í–‰': 0,
            'ì „ê¸°ì°¨_ì•„ë‹˜': 0,
            'í‘œì¤€í™”_ì‹¤íŒ¨': 0,
            'ì¬ì‹œë„_ì‹¤íŒ¨': 0
        }

        # ì œì™¸ëœ í–‰ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
        skipped_rows = []

        for row_idx, row in enumerate(rows):
            cells = row.find_all(['td', 'th'])
            if not cells:
                continue

            total_rows += 1
            row_data = {}

            # rowspan ê°’ë“¤ì˜ remaining ê°ì†Œ
            for col_idx in list(rowspan_values.keys()):
                rowspan_values[col_idx]['remaining'] -= 1
                if rowspan_values[col_idx]['remaining'] <= 0:
                    del rowspan_values[col_idx]

            # ê° í—¤ë” ì»¬ëŸ¼ì— ëŒ€í•´ ê°’ ì„¤ì • (rowspan ì²˜ë¦¬ ê°œì„ )
            cell_idx = 0
            for col_idx, header in enumerate(headers):
                if col_idx in rowspan_values:
                    # rowspanìœ¼ë¡œ ìœ ì§€ë˜ëŠ” ê°’ ì‚¬ìš©
                    row_data[header] = rowspan_values[col_idx]['value']
                elif cell_idx < len(cells):
                    # ìƒˆë¡œìš´ ì…€ ê°’ ì‚¬ìš©
                    cell = cells[cell_idx]
                    cell_text = cell.get_text(strip=True)
                    rowspan = int(cell.get('rowspan', 1))

                    row_data[header] = cell_text

                    # rowspanì´ 1ë³´ë‹¤ í¬ë©´ ì €ì¥
                    if rowspan > 1:
                        rowspan_values[col_idx] = {
                            'value': cell_text,
                            'remaining': rowspan - 1
                        }

                    cell_idx += 1
                else:
                    # ê°’ì´ ì—†ëŠ” ê²½ìš° ë¹ˆ ë¬¸ìì—´
                    row_data[header] = ''

            # ë””ë²„ê¹…: ë¬¸ì œê°€ ìˆëŠ” í–‰ ë¯¸ë¦¬ í™•ì¸
            if (row_data.get('ì°¨ì¢…', '').isdigit() or
                    row_data.get('ì œì¡°/ìˆ˜ì…ì‚¬', '').isdigit() or
                    (row_data.get('êµ¬ë¶„', '') and self._is_car_model_name(row_data.get('êµ¬ë¶„', '')))):
                print(f"ğŸ” rowspan ì˜¤ë¥˜ ì˜ì‹¬ í–‰: {row_data}")

            # ë¹ˆ í–‰ ì²´í¬
            if not any(value.strip() for value in row_data.values()):
                skipped_reasons['ë¹ˆ_í–‰'] += 1
                skipped_rows.append(('ë¹ˆ_í–‰', row_idx + 1, row_data))
                continue

            # ì „ê¸°ìë™ì°¨ í•„í„°ë§
            is_electric = False

            # ëª¨ë“  ì…€ ë‚´ìš©ì—ì„œ ì „ê¸°ì°¨ í‚¤ì›Œë“œ í™•ì¸
            all_text = ' '.join(row_data.values()).lower()
            for ek in electric_keywords:
                if ek.lower() in all_text:
                    is_electric = True
                    break

            # êµ¬ë¶„ì´ ìŠ¹ìš©, ê²½ì†Œí˜•ì¸ ê²½ìš° ì¶”ê°€ í™•ì¸ (ìˆ˜ì†Œì°¨ ì œì™¸)
            if not is_electric and 'êµ¬ë¶„' in row_data:
                category = row_data['êµ¬ë¶„'].lower()
                if any(cat in category for cat in ['ìŠ¹ìš©', 'ê²½', 'ì†Œí˜•']) and 'ìˆ˜ì†Œ' not in category and 'í™”ë¬¼' not in category:
                    # ì°¨ì¢…ëª…ì´ ìˆê³  ìˆ˜ì†Œì°¨ê°€ ì•„ë‹Œ ê²½ìš° ì „ê¸°ì°¨ë¡œ ê°„ì£¼
                    car_model = row_data.get('ì°¨ì¢…', '')
                    if car_model.strip() and 'ìˆ˜ì†Œ' not in car_model.lower():
                        is_electric = True

            # ì „ê¸°ì°¨ì¸ ê²½ìš°ì—ë§Œ ì¶”ê°€
            if is_electric:
                # ì œì¡°ì‚¬ ì •ë³´ ì—…ë°ì´íŠ¸ (rowspan ì¶”ì ìš©)
                if 'ì œì¡°/ìˆ˜ì…ì‚¬' in row_data and row_data['ì œì¡°/ìˆ˜ì…ì‚¬'].strip():
                    self._set_last_manufacturer(row_data['ì œì¡°/ìˆ˜ì…ì‚¬'])

                # êµ­ê³  ë³´ì¡°ê¸ˆê³¼ ì§€ìì²´ ë³´ì¡°ê¸ˆì˜ ì»¬ëŸ¼ëª… í†µì¼
                if subsidy_type == "ì§€ìì²´ ë³´ì¡°ê¸ˆ":
                    standardized_data = self._standardize_local_subsidy_data(row_data)
                else:
                    standardized_data = self._standardize_national_subsidy_data(row_data)

                if standardized_data:
                    data.append(standardized_data)
                    filtered_rows += 1
                    if len(data) <= 5:  # ì²˜ìŒ 5ê°œë§Œ ì¶œë ¥
                        print(f"âœ… ì¶”ê°€ë¨: {standardized_data}")
                else:
                    # í‘œì¤€í™” ì‹¤íŒ¨í•œ ê²½ìš° ì¶”ê°€ ì‹œë„
                    retry_data = self._retry_failed_standardization(row_data)
                    if retry_data:
                        data.append(retry_data)
                        filtered_rows += 1
                        print(f"âœ… ì¬ì‹œë„ ì„±ê³µ: {retry_data}")
                    else:
                        skipped_reasons['í‘œì¤€í™”_ì‹¤íŒ¨'] += 1
                        skipped_rows.append(('í‘œì¤€í™”_ì‹¤íŒ¨', row_idx + 1, row_data))
                        print(f"âŒ í‘œì¤€í™” ì‹¤íŒ¨: {row_data}")
            else:
                # ì „ê¸°ì°¨ê°€ ì•„ë‹Œ ê²½ìš°
                skipped_reasons['ì „ê¸°ì°¨_ì•„ë‹˜'] += 1
                skipped_rows.append(('ì „ê¸°ì°¨_ì•„ë‹˜', row_idx + 1, row_data))

                # ìˆ˜ì†Œì°¨ì¸ì§€ í™•ì¸
                if 'ìˆ˜ì†Œ' in all_text:
                    print(f"âšª ìˆ˜ì†Œì°¨ í•„í„°ë§ ({row_idx + 1}í–‰): {row_data}")
                else:
                    print(f"âšª ì „ê¸°ì°¨ í‚¤ì›Œë“œ ë¯¸ì¸ì‹ ({row_idx + 1}í–‰): {row_data}")

        print(f"ğŸ“Š {subsidy_type}: ì „ì²´ {total_rows}ê°œ í–‰ ì¤‘ ì „ê¸°ì°¨ {filtered_rows}ê°œ ì¶”ì¶œ")

        # ëˆ„ë½ëœ ë°ì´í„° ë¶„ì„
        missing_count = total_rows - filtered_rows
        if missing_count > 0:
            print(f"ğŸ” ëˆ„ë½ëœ {missing_count}ê°œ ë°ì´í„° ìƒì„¸ ë¶„ì„:")
            for reason, count in skipped_reasons.items():
                if count > 0:
                    print(f"   - {reason}: {count}ê°œ")

            # ì œì™¸ëœ í–‰ë“¤ ìƒì„¸ ì¶œë ¥
            print(f"\nğŸ“ ì œì™¸ëœ {len(skipped_rows)}ê°œ í–‰ ìƒì„¸ ë‚´ìš©:")
            for i, (reason, row_num, row_data) in enumerate(skipped_rows, 1):
                print(f"   {i}. í–‰ {row_num} ({reason}): {row_data}")

            # ëˆ„ë½ëœ ë°ì´í„°ê°€ ì ì€ ê²½ìš° ë” ìì„¸íˆ ë¶„ì„
            if missing_count <= 5:
                print(f"\nğŸ’¡ ì „ê¸°ì°¨ í‚¤ì›Œë“œ í™•ì¥ ê²€í† :")
                for reason, row_num, row_data in skipped_rows:
                    if reason == 'ì „ê¸°ì°¨_ì•„ë‹˜':
                        all_text = ' '.join(row_data.values()).lower()
                        print(f"   í–‰ {row_num}: '{all_text}'")

                        # ìˆ¨ê²¨ì§„ ì „ê¸°ì°¨ íŒ¨í„´ í™•ì¸
                        hidden_patterns = ['phev', 'hybrid', 'h2', 'fcev', 'bev', 'ev6', 'ioniq', 'id.', 'e-tron',
                                           'taycan']
                        for pattern in hidden_patterns:
                            if pattern in all_text:
                                print(f"      â†’ ë°œê²¬ëœ íŒ¨í„´: '{pattern}' (ì „ê¸°ì°¨ í‚¤ì›Œë“œ ì¶”ê°€ ê³ ë ¤)")
                                break

        print(f"âœ… {subsidy_type} ì „ê¸°ì°¨ ë°ì´í„° {len(data)}ê°œ ì¶”ì¶œ ì™„ë£Œ")
        return data

    def _retry_failed_standardization(self, row_data):
        """í‘œì¤€í™” ì‹¤íŒ¨í•œ ë°ì´í„° ì¬ì‹œë„"""
        # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ ì¬ì‹œë„
        attempts = [
            # ì‹œë„ 1: ëª¨ë“  í•„ë“œë¥¼ í•œ ì¹¸ì”© ë°€ê¸°
            {
                'ì°¨ëŸ‰êµ¬ë¶„': 'ìŠ¹ìš©',
                'ì œì¡°ì‚¬': self._get_previous_manufacturer(),
                'ëª¨ë¸ëª…': row_data.get('êµ¬ë¶„', ''),
                'êµ­ê³ ë³´ì¡°ê¸ˆ': row_data.get('ì œì¡°/ìˆ˜ì…ì‚¬', '')
            },
            # ì‹œë„ 2: ì œì¡°ì‚¬ì™€ ì°¨ì¢… ë°”ê¾¸ê¸°
            {
                'ì°¨ëŸ‰êµ¬ë¶„': row_data.get('êµ¬ë¶„', ''),
                'ì œì¡°ì‚¬': self._get_previous_manufacturer(),
                'ëª¨ë¸ëª…': row_data.get('ì œì¡°/ìˆ˜ì…ì‚¬', ''),
                'êµ­ê³ ë³´ì¡°ê¸ˆ': row_data.get('ì°¨ì¢…', '')
            },
            # ì‹œë„ 3: ì°¨ì¢…ê³¼ ë³´ì¡°ê¸ˆ ë°”ê¾¸ê¸°
            {
                'ì°¨ëŸ‰êµ¬ë¶„': row_data.get('êµ¬ë¶„', ''),
                'ì œì¡°ì‚¬': row_data.get('ì œì¡°/ìˆ˜ì…ì‚¬', ''),
                'ëª¨ë¸ëª…': row_data.get('êµ­ê³ ë³´ì¡°ê¸ˆ ì§€ì›ê¸ˆì•¡(ë§Œì›)', ''),
                'êµ­ê³ ë³´ì¡°ê¸ˆ': row_data.get('ì°¨ì¢…', '')
            }
        ]

        for attempt in attempts:
            if self._validate_standardized_data(attempt):
                return attempt

        return None

    def _standardize_national_subsidy_data(self, row_data):
        """êµ­ê³  ë³´ì¡°ê¸ˆ ë°ì´í„° í‘œì¤€í™” (rowspan ì˜¤ë¥˜ ì™„ì „ ë³µêµ¬)"""
        standardized = {}

        # ì›ë³¸ ë°ì´í„° ë¶„ì„
        category = row_data.get('êµ¬ë¶„', '').strip()
        manufacturer = row_data.get('ì œì¡°/ìˆ˜ì…ì‚¬', '').strip()
        model = row_data.get('ì°¨ì¢…', '').strip()
        subsidy = row_data.get('êµ­ê³ ë³´ì¡°ê¸ˆ ì§€ì›ê¸ˆì•¡(ë§Œì›)', '').strip()

        # rowspan ì˜¤ë¥˜ íŒ¨í„´ ê°ì§€ ë° ìˆ˜ì •
        if model.isdigit() and not subsidy:
            # íŒ¨í„´ 1: ì°¨ì¢… ìë¦¬ì— ë³´ì¡°ê¸ˆì´ ë“¤ì–´ê°„ ê²½ìš°
            print(f"ğŸ”§ rowspan ì˜¤ë¥˜ ê°ì§€ ë° ìˆ˜ì •: ì°¨ì¢…({model})ì´ ìˆ«ì")

            # ë°ì´í„° ì¬ë°°ì—´
            fixed_category = category if category in ['ìŠ¹ìš©', 'ê²½Â·ì†Œí˜•'] else 'ìŠ¹ìš©'  # ê¸°ë³¸ê°’
            fixed_manufacturer = self._get_previous_manufacturer()  # ì´ì „ ì œì¡°ì‚¬ ì‚¬ìš©
            fixed_model = manufacturer  # ì œì¡°ì‚¬ â†’ ëª¨ë¸ëª…
            fixed_subsidy = model  # ì°¨ì¢… â†’ ë³´ì¡°ê¸ˆ

            # ì œì¡°ì‚¬ê°€ ì‹¤ì œ ì°¨ì¢…ëª…ì¸ì§€ í™•ì¸
            if self._is_car_model_name(manufacturer):
                standardized = {
                    'ì°¨ëŸ‰êµ¬ë¶„': fixed_category,
                    'ì œì¡°ì‚¬': fixed_manufacturer,
                    'ëª¨ë¸ëª…': fixed_model,
                    'êµ­ê³ ë³´ì¡°ê¸ˆ': fixed_subsidy
                }
                print(f"âœ… ìˆ˜ì • ì™„ë£Œ: {standardized}")
                return standardized

        elif manufacturer.isdigit() and not subsidy:
            # íŒ¨í„´ 2: ì œì¡°ì‚¬ ìë¦¬ì— ë³´ì¡°ê¸ˆì´ ë“¤ì–´ê°„ ê²½ìš°
            print(f"ğŸ”§ rowspan ì˜¤ë¥˜ ê°ì§€ ë° ìˆ˜ì •: ì œì¡°ì‚¬({manufacturer})ê°€ ìˆ«ì")

            if self._is_car_model_name(category):
                standardized = {
                    'ì°¨ëŸ‰êµ¬ë¶„': 'ìŠ¹ìš©',  # ê¸°ë³¸ê°’
                    'ì œì¡°ì‚¬': self._get_previous_manufacturer(),
                    'ëª¨ë¸ëª…': category,  # êµ¬ë¶„ â†’ ëª¨ë¸ëª…
                    'êµ­ê³ ë³´ì¡°ê¸ˆ': manufacturer  # ì œì¡°ì‚¬ â†’ ë³´ì¡°ê¸ˆ
                }
                print(f"âœ… ìˆ˜ì • ì™„ë£Œ: {standardized}")
                return standardized

        # ìƒˆë¡œìš´ íŒ¨í„´ 3: êµ¬ë¶„ì— ì œì¡°ì‚¬ëª…ì´ ë“¤ì–´ê°€ê³  ì œì¡°ì‚¬ì— ëª¨ë¸ëª…ì´ ë“¤ì–´ê°„ ê²½ìš°
        elif self._is_manufacturer_name(category) and self._is_car_model_name(manufacturer):
            print(f"ğŸ”§ rowspan ì˜¤ë¥˜ ê°ì§€ ë° ìˆ˜ì •: êµ¬ë¶„({category})ì— ì œì¡°ì‚¬, ì œì¡°ì‚¬({manufacturer})ì— ëª¨ë¸ëª…")

            standardized = {
                'ì°¨ëŸ‰êµ¬ë¶„': 'ìŠ¹ìš©',  # ê¸°ë³¸ê°’
                'ì œì¡°ì‚¬': category,  # êµ¬ë¶„ â†’ ì œì¡°ì‚¬
                'ëª¨ë¸ëª…': manufacturer,  # ì œì¡°ì‚¬ â†’ ëª¨ë¸ëª…
                'êµ­ê³ ë³´ì¡°ê¸ˆ': model if model.isdigit() else '0'  # ì°¨ì¢… â†’ ë³´ì¡°ê¸ˆ
            }
            print(f"âœ… ìˆ˜ì • ì™„ë£Œ: {standardized}")
            return standardized

        # ìƒˆë¡œìš´ íŒ¨í„´ 4: êµ¬ë¶„ì— ëª¨ë¸ëª…ì´ ë“¤ì–´ê°€ê³  ì œì¡°ì‚¬ì— ë³´ì¡°ê¸ˆì´ ë“¤ì–´ê°„ ê²½ìš°
        elif self._is_car_model_name(category) and manufacturer.isdigit():
            print(f"ğŸ”§ rowspan ì˜¤ë¥˜ ê°ì§€ ë° ìˆ˜ì •: êµ¬ë¶„({category})ì— ëª¨ë¸ëª…, ì œì¡°ì‚¬({manufacturer})ì— ë³´ì¡°ê¸ˆ")

            standardized = {
                'ì°¨ëŸ‰êµ¬ë¶„': 'ìŠ¹ìš©',  # ê¸°ë³¸ê°’
                'ì œì¡°ì‚¬': self._get_previous_manufacturer(),  # ì´ì „ ì œì¡°ì‚¬ ì‚¬ìš©
                'ëª¨ë¸ëª…': category,  # êµ¬ë¶„ â†’ ëª¨ë¸ëª…
                'êµ­ê³ ë³´ì¡°ê¸ˆ': manufacturer  # ì œì¡°ì‚¬ â†’ ë³´ì¡°ê¸ˆ
            }
            print(f"âœ… ìˆ˜ì • ì™„ë£Œ: {standardized}")
            return standardized

        # ì •ìƒì ì¸ ê²½ìš° ë˜ëŠ” ë‹¤ë¥¸ íŒ¨í„´
        else:
            standardized = {
                'ì°¨ëŸ‰êµ¬ë¶„': category,
                'ì œì¡°ì‚¬': manufacturer,
                'ëª¨ë¸ëª…': model,
                'êµ­ê³ ë³´ì¡°ê¸ˆ': subsidy
            }

        # ì œì¡°ì‚¬ ì •ë³´ ì—…ë°ì´íŠ¸ (ë‹¤ìŒ í–‰ì—ì„œ ì‚¬ìš©)
        if manufacturer and not manufacturer.isdigit():
            self._set_last_manufacturer(manufacturer)

        # ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬
        if not self._validate_standardized_data(standardized):
            print(f"âš ï¸  í‘œì¤€í™” ì‹¤íŒ¨ ìƒì„¸: {standardized}")
            return None

        return standardized

    def _is_manufacturer_name(self, text):
        """í…ìŠ¤íŠ¸ê°€ ì œì¡°ì‚¬ëª…ì¸ì§€ íŒë‹¨"""
        if not text:
            return False

        # ì œì¡°ì‚¬ëª… ë¦¬ìŠ¤íŠ¸
        manufacturers = [
            'í˜„ëŒ€ìë™ì°¨', 'ê¸°ì•„', 'BMW', 'í…ŒìŠ¬ë¼ì½”ë¦¬ì•„', 'ë©”ë¥´ì„¸ë°ìŠ¤ë²¤ì¸ ì½”ë¦¬ì•„',
            'ì¼€ì´ì§€ëª¨ë¹Œë¦¬í‹°', 'í´ìŠ¤íƒ€ì˜¤í† ëª¨í‹°ë¸Œì½”ë¦¬ì•„', 'ë³¼ë³´ìë™ì°¨ì½”ë¦¬ì•„',
            'í­ìŠ¤ë°”ê²ê·¸ë£¹ì½”ë¦¬ì•„', 'ë¹„ì™€ì´ë””ì½”ë¦¬ì•„', 'BYD', 'í˜„ëŒ€', 'ê¸°ì•„ìë™ì°¨',
            'í…ŒìŠ¬ë¼', 'ë©”ë¥´ì„¸ë°ìŠ¤ë²¤ì¸ ', 'ë³¼ë³´', 'í´ìŠ¤íƒ€', 'í­ìŠ¤ë°”ê²'
        ]

        # ë¶€ë¶„ ë§¤ì¹­ë„ ê³ ë ¤
        for mfr in manufacturers:
            if mfr.lower() in text.lower() or text.lower() in mfr.lower():
                return True

        return False

    def _is_car_model_name(self, text):
        """í…ìŠ¤íŠ¸ê°€ ì°¨ëŸ‰ ëª¨ë¸ëª…ì¸ì§€ íŒë‹¨"""
        if not text or text.isdigit():
            return False

        # ì°¨ëŸ‰ ëª¨ë¸ëª… íŠ¹ì§•
        model_indicators = [
            'EV', 'electric', 'Electrified', 'e-tron', 'Model', 'GV60', 'GV70',
            'ì•„ì´ì˜¤ë‹‰', 'ë ˆì´', 'ì½”ë‚˜', 'KONA', 'ID.', 'i4', 'iX', 'MINI',
            'Polestar', 'EQA', 'EQB', 'ìºìŠ¤í¼', 'í† ë ˆìŠ¤', 'EVX', 'ë³¼ë³´', 'EX30',
            'ATTO', 'BYD', 'ì¼ë ‰íŠ¸ë¦­', 'ì „ê¸°', 'EV6', 'EV9', 'e-GMP', 'bZ4X',
            'Taycan', 'e-tron', 'EQS', 'EQC', 'EQV', 'iX3', 'i7', 'Polestar',
            'XC40', 'C40', 'EX90', 'EM90', 'Seal', 'Dolphin', 'Yuan', 'Song'
        ]

        # ëª¨ë¸ëª… í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆê±°ë‚˜ ê¸¸ì´ê°€ ì ì ˆí•œ ê²½ìš°
        if any(indicator.lower() in text.lower() for indicator in model_indicators):
            return True

        # ì ì ˆí•œ ê¸¸ì´ì˜ í…ìŠ¤íŠ¸ì´ê³  ìˆ«ìê°€ ì•„ë‹Œ ê²½ìš°
        if len(text) > 3 and not text.isdigit() and any(c.isalpha() for c in text):
            return True

        return False

    def _validate_standardized_data(self, data):
        """í‘œì¤€í™”ëœ ë°ì´í„° ìœ íš¨ì„± ê²€ì‚¬"""
        required_fields = ['ì°¨ëŸ‰êµ¬ë¶„', 'ì œì¡°ì‚¬', 'ëª¨ë¸ëª…', 'êµ­ê³ ë³´ì¡°ê¸ˆ']

        for field in required_fields:
            if field not in data or not data[field]:
                return False

        # ë³´ì¡°ê¸ˆì´ ìˆ«ìì¸ì§€ í™•ì¸
        if not data['êµ­ê³ ë³´ì¡°ê¸ˆ'].isdigit():
            return False

        # ì°¨ëŸ‰êµ¬ë¶„ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
        if data['ì°¨ëŸ‰êµ¬ë¶„'] not in ['ìŠ¹ìš©', 'ê²½Â·ì†Œí˜•']:
            return False

        # ëª¨ë¸ëª…ì´ ìˆ«ìë§Œìœ¼ë¡œ êµ¬ì„±ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸
        if data['ëª¨ë¸ëª…'].isdigit():
            return False

        return True

    def _get_previous_manufacturer(self):
        """ì´ì „ì— ì²˜ë¦¬ëœ ì œì¡°ì‚¬ëª… ë°˜í™˜ (rowspan ì˜¤ë¥˜ ë³µêµ¬ìš©)"""
        if not hasattr(self, '_last_manufacturer'):
            # ê¸°ë³¸ê°’ë“¤ ì¤‘ì—ì„œ ì„ íƒ
            self._last_manufacturer = 'í˜„ëŒ€ìë™ì°¨'
        return self._last_manufacturer

    def _set_last_manufacturer(self, manufacturer):
        """ë§ˆì§€ë§‰ ì œì¡°ì‚¬ëª… ì €ì¥"""
        # ìœ íš¨í•œ ì œì¡°ì‚¬ëª…ë§Œ ì €ì¥
        valid_manufacturers = [
            'í˜„ëŒ€ìë™ì°¨', 'ê¸°ì•„', 'BMW', 'í…ŒìŠ¬ë¼ì½”ë¦¬ì•„', 'ë©”ë¥´ì„¸ë°ìŠ¤ë²¤ì¸ ì½”ë¦¬ì•„',
            'ì¼€ì´ì§€ëª¨ë¹Œë¦¬í‹°', 'í´ìŠ¤íƒ€ì˜¤í† ëª¨í‹°ë¸Œì½”ë¦¬ì•„', 'ë³¼ë³´ìë™ì°¨ì½”ë¦¬ì•„',
            'í­ìŠ¤ë°”ê²ê·¸ë£¹ì½”ë¦¬ì•„', 'ë¹„ì™€ì´ë””ì½”ë¦¬ì•„'
        ]

        if manufacturer and any(mfr in manufacturer for mfr in valid_manufacturers):
            self._last_manufacturer = manufacturer

    def _standardize_local_subsidy_data(self, row_data):
        """ì§€ìì²´ ë³´ì¡°ê¸ˆ ë°ì´í„° í‘œì¤€í™” (ì „ê¸°ì°¨ë§Œ, ìˆ˜ì†Œì°¨ ì œì™¸)"""
        standardized = {}

        # ì§€ìì²´ ë³´ì¡°ê¸ˆì˜ ì»¬ëŸ¼ êµ¬ì¡°ì— ë§ê²Œ ë§¤í•‘ (ì „ê¸°ì°¨ë§Œ)
        column_mapping = {
            'ì‹œë„': 'ì§€ì—­',
            'ì „ê¸°ìë™ì°¨': 'ì „ê¸°ì°¨ë³´ì¡°ê¸ˆ'
        }

        for original_key, standard_key in column_mapping.items():
            if original_key in row_data and row_data[original_key].strip():
                value = row_data[original_key].strip()
                if standard_key == 'ì§€ì—­':  # ì§€ì—­ëª…ì€ í•­ìƒ í¬í•¨
                    standardized[standard_key] = value
                elif value and value != '-' and value != 'ë¯¸ì§€ì›' and any(c.isdigit() for c in value):
                    # ì „ê¸°ì°¨ ë³´ì¡°ê¸ˆë§Œ í¬í•¨ (ìˆ«ìê°€ í¬í•¨ëœ ê²½ìš°)
                    # ë³´ì¡°ê¸ˆ ë°ì´í„° ì •ì œ
                    cleaned_subsidy = self._clean_subsidy_amount(value)
                    if cleaned_subsidy:
                        standardized[standard_key] = cleaned_subsidy

        # ì§€ìì²´ ë³´ì¡°ê¸ˆì˜ ê²½ìš° ì§€ì—­ê³¼ ì „ê¸°ì°¨ë³´ì¡°ê¸ˆì´ ëª¨ë‘ ìˆì–´ì•¼ í•¨
        if 'ì§€ì—­' in standardized and 'ì „ê¸°ì°¨ë³´ì¡°ê¸ˆ' in standardized:
            return standardized
        return None

    def _clean_subsidy_amount(self, amount_str):
        """ë³´ì¡°ê¸ˆ ê¸ˆì•¡ ë°ì´í„° ì •ì œ"""
        if not amount_str:
            return None

        # ë¬¸ìì—´ ì •ì œ
        cleaned = amount_str.strip()

        # ìŒë”°ì˜´í‘œ ì œê±°
        cleaned = cleaned.replace('"', '').replace("'", "")

        # ì‰¼í‘œ ì œê±° (1,100 â†’ 1100)
        cleaned = cleaned.replace(',', '')

        # ë²”ìœ„ í‘œì‹œ(~)ê°€ ìˆëŠ” ê²½ìš° ìµœì†Œê°’ë§Œ ì¶”ì¶œ
        if '~' in cleaned:
            # "200~484" â†’ "200"
            min_amount = cleaned.split('~')[0].strip()
            cleaned = min_amount

        # ìˆ«ìë§Œ ì¶”ì¶œ (ë‹¨ìœ„ ì œê±°)
        import re
        numbers = re.findall(r'\d+\.?\d*', cleaned)

        if numbers:
            # ì²« ë²ˆì§¸ ìˆ«ì ì‚¬ìš© (ì†Œìˆ˜ì  ì²˜ë¦¬)
            amount = numbers[0]

            # ì†Œìˆ˜ì ì´ ìˆëŠ” ê²½ìš° ì •ìˆ˜ë¡œ ë³€í™˜
            if '.' in amount:
                amount = str(int(float(amount)))

            return amount

        return None

    def load_existing_data(self, file_path):
        """ê¸°ì¡´ ë°ì´í„° ë¡œë“œ"""
        if os.path.exists(file_path):
            try:
                return pd.read_csv(file_path, encoding='utf-8-sig')
            except Exception as e:
                print(f"âš ï¸  ê¸°ì¡´ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜ ({file_path}): {e}")
                return pd.DataFrame()
        return pd.DataFrame()

    def update_data(self, new_data, existing_df, subsidy_type):
        """ë°ì´í„° ì—…ë°ì´íŠ¸"""
        if not new_data:
            print(f"âš ï¸  {subsidy_type}: ìƒˆ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return existing_df, False

        new_df = pd.DataFrame(new_data)

        # ìƒˆ ë°ì´í„° í•´ì‹œ ê³„ì‚°
        new_hash = self.calculate_data_hash(new_data)

        # ê¸°ì¡´ í•´ì‹œì™€ ë¹„êµ
        hash_key = 'national_hash' if subsidy_type == 'êµ­ê³  ë³´ì¡°ê¸ˆ' else 'local_hash'
        if self.metadata.get(hash_key) == new_hash:
            print(f"â„¹ï¸  {subsidy_type}: ë°ì´í„° ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
            return existing_df, False

        # í•´ì‹œ ì—…ë°ì´íŠ¸
        self.metadata[hash_key] = new_hash

        if existing_df.empty:
            print(f"ğŸ†• {subsidy_type}: ìƒˆë¡œìš´ ë°ì´í„°ì…‹ ìƒì„±")
            return new_df, True

        print(f"ğŸ”„ {subsidy_type}: ì „ì²´ ë°ì´í„° ì—…ë°ì´íŠ¸")
        return new_df, True

    def save_data(self, df, file_path, subsidy_type):
        """ë°ì´í„° ì €ì¥ (CSV + êµ¬ê¸€ ì‹œíŠ¸)"""
        try:
            # CSV ì €ì¥ (ê¸°ì¡´)
            df.to_csv(file_path, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ {subsidy_type} ë°ì´í„° ì €ì¥ ì™„ë£Œ: {file_path}")

            # DataFrame ì •ë³´ ì¶œë ¥ (ë””ë²„ê¹…)
            print(f"ğŸ” {subsidy_type} DataFrame ì •ë³´:")
            print(f"   - íƒ€ì…: {type(df)}")
            print(f"   - í¬ê¸°: {df.shape}")
            print(f"   - ì»¬ëŸ¼: {list(df.columns)}")
            print(f"   - ë¹„ì–´ìˆìŒ: {df.empty}")
            if not df.empty:
                print(f"   - ì²« ë²ˆì§¸ í–‰: {df.iloc[0].to_dict()}")

            # êµ¬ê¸€ ì‹œíŠ¸ ì €ì¥ (ì¶”ê°€)
            if self.sheets_manager:
                print(f"ğŸ“Š {subsidy_type} êµ¬ê¸€ ì‹œíŠ¸ ì—…ë¡œë“œ ì‹œì‘...")
                if subsidy_type == "êµ­ê³  ë³´ì¡°ê¸ˆ":
                    self.sheets_manager.upload_national_subsidy(df)
                elif subsidy_type == "ì§€ìì²´ ë³´ì¡°ê¸ˆ":
                    self.sheets_manager.upload_local_subsidy(df)
                print(f"ğŸ“Š {subsidy_type} êµ¬ê¸€ ì‹œíŠ¸ ì—…ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"âš ï¸ {subsidy_type}: êµ¬ê¸€ ì‹œíŠ¸ ë§¤ë‹ˆì €ê°€ ì—†ìŒ")

        except Exception as e:
            print(f"âŒ {subsidy_type} ë°ì´í„° ì €ì¥ ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()

    def debug_page_structure(self, soup, save_to_file=True):
        """í˜ì´ì§€ êµ¬ì¡° ë””ë²„ê¹… ë° ë¶„ì„"""
        print("\n" + "=" * 60)
        print("ğŸ” í˜ì´ì§€ êµ¬ì¡° ë””ë²„ê¹…")
        print("=" * 60)

        debug_info = []

        # 1. ëª¨ë“  div íƒœê·¸ ë¶„ì„
        all_divs = soup.find_all('div')
        debug_info.append(f"ì´ div íƒœê·¸ ìˆ˜: {len(all_divs)}")

        # 2. class ì†ì„±ì´ ìˆëŠ” div ë¶„ì„
        class_divs = soup.find_all('div', class_=True)
        debug_info.append(f"class ì†ì„±ì´ ìˆëŠ” div ìˆ˜: {len(class_divs)}")

        # 3. subWrap ê´€ë ¨ div ì°¾ê¸°
        subwrap_divs = soup.find_all('div', class_=lambda x: x and 'subWrap' in ' '.join(x) if isinstance(x,
                                                                                                          list) else 'subWrap' in x if x else False)
        debug_info.append(f"subWrap ê´€ë ¨ div ìˆ˜: {len(subwrap_divs)}")

        for i, div in enumerate(subwrap_divs):
            class_name = ' '.join(div.get('class', []))
            debug_info.append(f"  - subWrap div {i + 1}: class='{class_name}'")

        # 4. í…Œì´ë¸” ë¶„ì„
        tables = soup.find_all('table')
        debug_info.append(f"ì´ table íƒœê·¸ ìˆ˜: {len(tables)}")

        table01_tables = soup.find_all('table', class_='table01 fz15')
        debug_info.append(f"table01 fz15 í´ë˜ìŠ¤ í…Œì´ë¸” ìˆ˜: {len(table01_tables)}")

        # 5. ê° í…Œì´ë¸”ì˜ í—¤ë” ë¶„ì„
        for i, table in enumerate(table01_tables):
            debug_info.append(f"\n--- í…Œì´ë¸” {i + 1} ë¶„ì„ ---")

            # í—¤ë” ì¶”ì¶œ
            header_row = table.find('thead')
            if header_row:
                headers = [th.get_text(strip=True) for th in header_row.find_all(['th', 'td'])]
            else:
                first_row = table.find('tr')
                headers = [td.get_text(strip=True) for td in first_row.find_all(['th', 'td'])] if first_row else []

            debug_info.append(f"í—¤ë”: {headers}")

            # ë°ì´í„° í–‰ ìˆ˜ í™•ì¸
            tbody = table.find('tbody')
            if tbody:
                rows = tbody.find_all('tr')
            else:
                rows = table.find_all('tr')[1:] if len(table.find_all('tr')) > 1 else []

            debug_info.append(f"ë°ì´í„° í–‰ ìˆ˜: {len(rows)}")

            # ì²« ë²ˆì§¸ ë°ì´í„° í–‰ ìƒ˜í”Œ
            if rows:
                first_row_data = [td.get_text(strip=True) for td in rows[0].find_all(['td', 'th'])]
                debug_info.append(f"ì²« ë²ˆì§¸ í–‰ ë°ì´í„°: {first_row_data}")

        # 6. í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰
        page_text = soup.get_text()
        keywords = ['êµ­ê³ ', 'ì§€ìì²´', 'ì „ê¸°', 'ìˆ˜ì†Œ', 'ë³´ì¡°ê¸ˆ']
        for keyword in keywords:
            count = page_text.count(keyword)
            debug_info.append(f"'{keyword}' í‚¤ì›Œë“œ ë“±ì¥ íšŸìˆ˜: {count}")

        # ì¶œë ¥
        for info in debug_info:
            print(info)

        # íŒŒì¼ë¡œ ì €ì¥
        if save_to_file:
            debug_file = os.path.join(self.data_dir, 'debug_page_structure.txt')
            with open(debug_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(debug_info))
                f.write('\n\n--- ì „ì²´ HTML êµ¬ì¡° ---\n')
                f.write(soup.prettify())
            print(f"ğŸ“ ë””ë²„ê·¸ ì •ë³´ê°€ {debug_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

        print("=" * 60 + "\n")
        return debug_info

    def generate_report(self, national_df, local_df, method_used):
        """ìˆ˜ì§‘ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = {
            'timestamp': datetime.now().isoformat(),
            'method_used': method_used,
            'national_subsidy': {
                'count': len(national_df) if not national_df.empty else 0,
                'columns': list(national_df.columns) if not national_df.empty else []
            },
            'local_subsidy': {
                'count': len(local_df) if not local_df.empty else 0,
                'columns': list(local_df.columns) if not local_df.empty else []
            }
        }

        print("\n" + "=" * 60)
        print("ğŸ“Š ì „ê¸°ì°¨ ë³´ì¡°ê¸ˆ ìˆ˜ì§‘ ê²°ê³¼ ë¦¬í¬íŠ¸")
        print("=" * 60)
        print(f"ğŸ• ìˆ˜ì§‘ ì‹œê°„: {report['timestamp']}")
        print(f"ğŸ”§ ì‚¬ìš© ë°©ë²•: {report['method_used']}")
        print(f"ğŸ›ï¸  êµ­ê³  ë³´ì¡°ê¸ˆ: {report['national_subsidy']['count']}ê°œ í•­ëª©")
        print(f"ğŸ¢ ì§€ìì²´ ë³´ì¡°ê¸ˆ: {report['local_subsidy']['count']}ê°œ í•­ëª©")

        if not national_df.empty:
            print(f"ğŸ“‹ êµ­ê³  ë³´ì¡°ê¸ˆ ì»¬ëŸ¼: {', '.join(report['national_subsidy']['columns'])}")

        if not local_df.empty:
            print(f"ğŸ“‹ ì§€ìì²´ ë³´ì¡°ê¸ˆ ì»¬ëŸ¼: {', '.join(report['local_subsidy']['columns'])}")

        # JavaScript í•„ìš” ê²½ê³ 
        if method_used == 'requests' and (
                report['national_subsidy']['count'] < 50 or report['local_subsidy']['count'] == 0):
            print("\nâš ï¸  ê²½ê³ : requests ë°©ë²•ìœ¼ë¡œëŠ” JavaScriptê°€ í•„ìš”í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ’¡ ë” ë§ì€ ë°ì´í„°ë¥¼ ìœ„í•´ ë‹¤ìŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤:")
            print("   /opt/anaconda3/bin/pip install requests-html")
            print("   ë˜ëŠ”")
            print(
                "   /opt/anaconda3/bin/pip install playwright && /opt/anaconda3/bin/python -m playwright install chromium")

        print("=" * 60 + "\n")
        return report

    def run(self, method=None, debug_mode=False, verbose_missing=False):
        """ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        # verbose_missing ì„¤ì •ì„ ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ë¡œ ì €ì¥
        self.verbose_missing = verbose_missing

        # ë°©ë²• ì„ íƒ
        selected_method = method if method else self._select_method()

        if selected_method not in self.available_methods:
            print(f"âŒ ì„ íƒí•œ ë°©ë²• '{selected_method}'ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print(f"ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: {', '.join(self.available_methods)}")
            return None, None

        print(f"ğŸš€ ì „ê¸°ì°¨ ë³´ì¡°ê¸ˆ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ (ë°©ë²•: {selected_method})")
        print(f"ğŸ“ˆ ì‹¤í–‰ íšŸìˆ˜: {self.metadata['total_runs'] + 1}")
        if debug_mode:
            print("ğŸ› ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”")
        if verbose_missing:
            print("ğŸ” ëˆ„ë½ ë°ì´í„° ìƒì„¸ ë¶„ì„ ëª¨ë“œ í™œì„±í™”")

        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        existing_national = self.load_existing_data(self.national_file)
        existing_local = self.load_existing_data(self.local_file)

        # ì„ íƒëœ ë°©ë²•ìœ¼ë¡œ í¬ë¡¤ë§ ì‹¤í–‰
        national_data, local_data = None, None
        soup = None  # ë””ë²„ê¹…ìš©

        if selected_method == 'requests':
            national_data, local_data = self.crawl_with_requests()
        elif selected_method == 'requests-html':
            result = self.crawl_with_requests_html()
            if result and len(result) == 3:  # soupë„ í•¨ê»˜ ë°˜í™˜í•˜ë„ë¡ ìˆ˜ì •ëœ ê²½ìš°
                national_data, local_data, soup = result
            else:
                national_data, local_data = result if result else (None, None)
        elif selected_method == 'playwright':
            national_data, local_data = self.crawl_with_playwright()
        elif selected_method == 'pyppeteer':
            national_data, local_data = self.crawl_with_pyppeteer()

        # ë””ë²„ê·¸ ëª¨ë“œì¸ ê²½ìš° í˜ì´ì§€ êµ¬ì¡° ë¶„ì„
        if debug_mode and soup:
            self.debug_page_structure(soup)

        # ì‹¤íŒ¨ì‹œ ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì‹œë„
        if (not national_data and not local_data) and selected_method != 'requests':
            print(f"âš ï¸  {selected_method} ì‹¤íŒ¨, ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ì¬ì‹œë„...")

            for fallback_method in ['requests-html', 'playwright', 'requests']:
                if fallback_method != selected_method and fallback_method in self.available_methods:
                    print(f"ğŸ”„ {fallback_method} ë°©ë²•ìœ¼ë¡œ ì¬ì‹œë„...")

                    if fallback_method == 'requests':
                        national_data, local_data = self.crawl_with_requests()
                    elif fallback_method == 'requests-html':
                        national_data, local_data = self.crawl_with_requests_html()
                    elif fallback_method == 'playwright':
                        national_data, local_data = self.crawl_with_playwright()

                    if national_data or local_data:
                        selected_method = fallback_method
                        break

        if not national_data and not local_data:
            print("âŒ ëª¨ë“  ë°©ë²•ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            return None, None

        # ë°ì´í„° ì—…ë°ì´íŠ¸
        updated_national, national_changed = self.update_data(national_data, existing_national, "êµ­ê³  ë³´ì¡°ê¸ˆ")
        updated_local, local_changed = self.update_data(local_data, existing_local, "ì§€ìì²´ ë³´ì¡°ê¸ˆ")

        # ë³€ê²½ì‚¬í•­ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì €ì¥
        if national_changed:
            self.save_data(updated_national, self.national_file, "êµ­ê³  ë³´ì¡°ê¸ˆ")

        if local_changed:
            self.save_data(updated_local, self.local_file, "ì§€ìì²´ ë³´ì¡°ê¸ˆ")

        # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        self.metadata['last_updated'] = datetime.now().isoformat()
        self.metadata['total_runs'] += 1
        self.metadata['method_used'] = selected_method
        self.save_metadata()

        # ë¦¬í¬íŠ¸ ìƒì„±
        report = self.generate_report(updated_national, updated_local, selected_method)

        print("âœ… í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")
        return updated_national, updated_local


# ì‚¬ìš© ì˜ˆì‹œ ë° ì‹¤í–‰ ë¶€ë¶„
if __name__ == "__main__":
    print("ğŸš— ì „ê¸°ì°¨ ë³´ì¡°ê¸ˆ í¬ë¡¤ë§ ì‹œìŠ¤í…œ (ê°œì„ ëœ ë²„ì „)")
    print("=" * 50)

    # êµ¬ê¸€ ì‹œíŠ¸ ì„¤ì • (ê¸°ë³¸ í™œì„±í™”)
    USE_GOOGLE_SHEETS = True  # ê¸°ë³¸ì ìœ¼ë¡œ êµ¬ê¸€ ì‹œíŠ¸ ì‚¬ìš©
    CREDENTIALS_FILE = "/Users/cullen/Documents/eccc/youtube-search-api-447606-43654b5c40cc.json"  # ì‹¤ì œ JSON ê²½ë¡œ
    SPREADSHEET_ID = "1KqwyiVutE4_pCwNnAi5DZS0u7SbugLOCpCPDk3vI4AM"  # ì‹¤ì œ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID

    # êµ¬ê¸€ ì‹œíŠ¸ ë¹„í™œì„±í™” ì˜µì…˜ (í•„ìš”í•œ ê²½ìš°)
    if '--no-google-sheets' in sys.argv:
        USE_GOOGLE_SHEETS = False
        print("ğŸ“ CSV ì „ìš© ëª¨ë“œ (êµ¬ê¸€ ì‹œíŠ¸ ë¹„í™œì„±í™”)")

    # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ IDê°€ ëª…ë ¹í–‰ ì¸ìˆ˜ë¡œ ì œê³µëœ ê²½ìš° (ë®ì–´ì“°ê¸°)
    for i, arg in enumerate(sys.argv):
        if arg == '--spreadsheet-id' and i + 1 < len(sys.argv):
            SPREADSHEET_ID = sys.argv[i + 1]
            print(f"ğŸ“„ ì‚¬ìš©ì ì§€ì • ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID: {SPREADSHEET_ID}")
            break

    # ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
    if USE_GOOGLE_SHEETS and SPREADSHEET_ID:
        print("ğŸ“Š êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ ëª¨ë“œ (ê¸°ë³¸)")
        print(f"ğŸ“„ ìŠ¤í”„ë ˆë“œì‹œíŠ¸: https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/")
        try:
            manager = EVSubsidyManager(
                method='auto',
                use_google_sheets=True,
                credentials_file=CREDENTIALS_FILE,
                spreadsheet_id=SPREADSHEET_ID
            )
        except Exception as e:
            print(f"âš ï¸ êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ ì‹¤íŒ¨, CSVë§Œ ì €ì¥: {e}")
            manager = EVSubsidyManager(method='auto')
    else:
        print("ğŸ“ CSV ì „ìš© ëª¨ë“œ")
        manager = EVSubsidyManager(method='auto')

    # ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²• ì¶œë ¥
    print(f"ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ë°©ë²•: {', '.join(manager.available_methods)}")

    # JavaScript ë Œë”ë§ ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    js_methods = [m for m in manager.available_methods if m in ['requests-html', 'playwright', 'pyppeteer']]
    if not js_methods:
        print("âš ï¸  JavaScript ë Œë”ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ ë” ë§ì€ ë°ì´í„° ìˆ˜ì§‘ì„ ìœ„í•´ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("   /opt/anaconda3/bin/pip install requests-html     (ê°€ì¥ ê°„ë‹¨)")
        print(
            "   /opt/anaconda3/bin/pip install playwright && /opt/anaconda3/bin/python -m playwright install chromium  (ê³ ì„±ëŠ¥)")
        print("")

        # ì‚¬ìš©ì ì„ íƒ
        user_choice = input("ê·¸ë˜ë„ ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
        if user_choice not in ['y', 'yes', 'ë„¤', 'ã…‡']:
            print("ì„¤ì¹˜ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            sys.exit(0)

    # ë””ë²„ê·¸ ëª¨ë“œ ì˜µì…˜
    debug_mode = '--debug' in sys.argv or '-d' in sys.argv
    verbose_missing = '--verbose' in sys.argv or '-v' in sys.argv

    if debug_mode:
        print("ğŸ› ë””ë²„ê·¸ ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘...")

    if verbose_missing:
        print("ğŸ” ëˆ„ë½ ë°ì´í„° ìƒì„¸ ë¶„ì„ ëª¨ë“œë¡œ ì‹¤í–‰ ì¤‘...")

    # ì‹¤í–‰
    national_df, local_df = manager.run(debug_mode=debug_mode, verbose_missing=verbose_missing)

    # ê²°ê³¼ í™•ì¸
    if national_df is not None and not national_df.empty:
        print(f"\nğŸ›ï¸  êµ­ê³  ë³´ì¡°ê¸ˆ ì „ê¸°ì°¨ ë°ì´í„°:")
        print(f"   ì´ {len(national_df)}ê°œ í•­ëª©")
        print("\nğŸ“‹ ì»¬ëŸ¼ ì •ë³´:")
        for col in national_df.columns:
            print(f"   - {col}")
        print(f"\nğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
        print(national_df.head(3).to_string(index=False))

        # ë°ì´í„°ê°€ ì ì€ ê²½ìš° ê²½ê³ 
        if len(national_df) < 10:
            print(f"\nâš ï¸  ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì ìŠµë‹ˆë‹¤ ({len(national_df)}ê°œ)")
            print("ğŸ’¡ JavaScript ë Œë”ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤:")
            print("   /opt/anaconda3/bin/pip install requests-html")
    else:
        print("âŒ êµ­ê³  ë³´ì¡°ê¸ˆ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    if local_df is not None and not local_df.empty:
        print(f"\nğŸ¢ ì§€ìì²´ ë³´ì¡°ê¸ˆ ì „ê¸°ì°¨ ë°ì´í„°:")
        print(f"   ì´ {len(local_df)}ê°œ í•­ëª©")
        print("\nğŸ“‹ ì»¬ëŸ¼ ì •ë³´:")
        for col in local_df.columns:
            print(f"   - {col}")
        print(f"\nğŸ” ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
        print(local_df.head(3).to_string(index=False))
    else:
        print("âŒ ì§€ìì²´ ë³´ì¡°ê¸ˆ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ğŸ’¡ JavaScript ë Œë”ë§ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    print(f"\nğŸ“ ë°ì´í„° ì €ì¥ ìœ„ì¹˜: {manager.data_dir}")

    # ìµœì¢… ê¶Œì¥ì‚¬í•­
    total_items = len(national_df) if national_df is not None else 0
    total_items += len(local_df) if local_df is not None else 0

    if total_items < 20:
        print(f"\nğŸ’¡ ìˆ˜ì§‘ëœ ì´ ë°ì´í„°: {total_items}ê°œ")
        print("ë” ë§ì€ ë°ì´í„°ë¥¼ ìœ„í•´ JavaScript ë Œë”ë§ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:")
        print("/opt/anaconda3/bin/pip install requests-html")

    print("ğŸ‰ í¬ë¡¤ë§ ì™„ë£Œ!")

    # êµ¬ê¸€ ì‹œíŠ¸ ì—°ë™ëœ ê²½ìš° ë§í¬ í‘œì‹œ
    if manager.sheets_manager:
        print(f"ğŸ“Š êµ¬ê¸€ ì‹œíŠ¸ì—ì„œ í™•ì¸: https://docs.google.com/spreadsheets/d/{SPREADSHEET_ID}/")
        print("ğŸ’¡ íŒ€ì›ë“¤ê³¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë°ì´í„°ë¥¼ ê³µìœ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!")

    if debug_mode:
        print(f"\nğŸ’¡ ë””ë²„ê·¸ íŒŒì¼ í™•ì¸: {os.path.join(manager.data_dir, 'debug_page_structure.txt')}")